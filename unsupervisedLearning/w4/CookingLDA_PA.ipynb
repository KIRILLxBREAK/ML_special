{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment\n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза <<мешка слов>>. Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать <<мешком ингредиентов>>, потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные <<темы>>. Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули json и gensim. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "pip install gensim\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (\"cuisine\") и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(recipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая и влезает в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = dictionary.token2id['pepper']\n",
    "# print(i)\n",
    "# dictionary.id2token[i]\n",
    "# dictionary.token2id\n",
    "# texts\n",
    "test_text = [['romaine lettuce',\n",
    "  'black olives',\n",
    "  'grape tomatoes',\n",
    "  'garlic',\n",
    "  'pepper',\n",
    "  'purple onion',\n",
    "  'seasoning',\n",
    "  'garbanzo beans',\n",
    "  'feta cheese crumbles'],\n",
    " ['plain flour',\n",
    "  'ground pepper',\n",
    "  'salt',\n",
    "  'tomatoes',\n",
    "  'ground black pepper',\n",
    "  'thyme',\n",
    "  'eggs',\n",
    "  'green tomatoes',\n",
    "  'yellow corn meal',\n",
    "  'milk']]\n",
    "\n",
    "test_dictionary = corpora.Dictionary(test_text) \n",
    "test_dictionary.id2token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: dictionary.id2token и dictionary.token2id; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. Затем вызовите метод модели show_topics, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода show_topics указать параметр formatted=True, то топы ингредиентов будет удобно выводить на печать, если formatted=False, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ae35dd3bfd17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# c2 = np.average([c[1] for c in coherence2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoherence2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%3f %3f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers, not tuple"
     ]
    }
   ],
   "source": [
    "##Floatdrop:\n",
    "np.random.seed(76543)\n",
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)\n",
    "over4000 = [k for k,v in dictionary.dfs.items() if v > 4000]\n",
    "dictionary2.filter_tokens(over4000)\n",
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]  # составляем корпус документов\n",
    "# lda  = models.LdaModel(corpus, num_topics=40, passes=5)\n",
    "lda2 = models.LdaModel(corpus2, num_topics=40, passes=5)\n",
    "# coherence = lda.top_topics(corpus)\n",
    "coherence2 = lda2.top_topics(corpus2)\n",
    "# c1 = np.average([c[1] for c in coherence])\n",
    "# c2 = np.average([c[1] for c in coherence2])\n",
    "c1 = 0\n",
    "c2 = np.array(coherence2[:,1]).mean()\n",
    "print(\"%3f %3f\" %(c1, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000 -668.258775\n"
     ]
    }
   ],
   "source": [
    "c1 = 0\n",
    "c2 = np.array(coherence2)[:,1].mean()\n",
    "print(\"%3f %3f\" %(c1, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-668.25877450753126"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([c[1] for c in coherence2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=40, passes=5)\n",
    "# lda = models.LdaModel(corpus=corpus, num_topics=40, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('17', 0.082725546797489391),\n",
       "   ('116', 0.080315765339626533),\n",
       "   ('100', 0.079497577421526855),\n",
       "   ('54', 0.063701738565159538),\n",
       "   ('279', 0.063698834149618494),\n",
       "   ('119', 0.035428696876100417),\n",
       "   ('307', 0.034279080876904885),\n",
       "   ('29', 0.034236340577608278),\n",
       "   ('38', 0.033008901590063464),\n",
       "   ('12', 0.031967658022379206)]),\n",
       " (1,\n",
       "  [('195', 0.1301630328824499),\n",
       "   ('45', 0.07742758767320175),\n",
       "   ('178', 0.052235425972973433),\n",
       "   ('124', 0.04311400910741036),\n",
       "   ('211', 0.03975648683471391),\n",
       "   ('29', 0.038824867680195226),\n",
       "   ('958', 0.03651279483658941),\n",
       "   ('705', 0.031274197021606727),\n",
       "   ('17', 0.029083608761412482),\n",
       "   ('1493', 0.025696170959706201)]),\n",
       " (2,\n",
       "  [('770', 0.065976910937656216),\n",
       "   ('830', 0.046548563175849753),\n",
       "   ('1338', 0.04559577697003106),\n",
       "   ('480', 0.044639430969227956),\n",
       "   ('3', 0.044296605936575029),\n",
       "   ('1637', 0.039024793030259783),\n",
       "   ('816', 0.034564495735168059),\n",
       "   ('806', 0.032915117949667574),\n",
       "   ('117', 0.029791949970061241),\n",
       "   ('1201', 0.029551099169572707)]),\n",
       " (3,\n",
       "  [('41', 0.11680479719535167),\n",
       "   ('207', 0.11246226731277101),\n",
       "   ('17', 0.080664949323854263),\n",
       "   ('383', 0.049927492451083626),\n",
       "   ('0', 0.048956382781642882),\n",
       "   ('45', 0.048176782493226218),\n",
       "   ('155', 0.045778810707977846),\n",
       "   ('29', 0.029528053284775441),\n",
       "   ('425', 0.029097361493563022),\n",
       "   ('397', 0.029056512568765441)]),\n",
       " (4,\n",
       "  [('200', 0.060701202478307417),\n",
       "   ('20', 0.056556523215000848),\n",
       "   ('17', 0.055464595931986792),\n",
       "   ('39', 0.05364391417341325),\n",
       "   ('45', 0.039306025072256674),\n",
       "   ('348', 0.034363248636521453),\n",
       "   ('183', 0.031722436012575309),\n",
       "   ('236', 0.030095138443782553),\n",
       "   ('216', 0.026637303062034955),\n",
       "   ('12', 0.02619895761516185)]),\n",
       " (5,\n",
       "  [('46', 0.073224232561434191),\n",
       "   ('17', 0.052710383064241147),\n",
       "   ('113', 0.047504904991452185),\n",
       "   ('183', 0.041184558938963459),\n",
       "   ('54', 0.037786494541740788),\n",
       "   ('45', 0.035301772346616335),\n",
       "   ('4', 0.032634127249167456),\n",
       "   ('39', 0.022796340837944174),\n",
       "   ('100', 0.021645248806059551),\n",
       "   ('127', 0.020400486692637353)]),\n",
       " (6,\n",
       "  [('51', 0.1129934634102762),\n",
       "   ('366', 0.086847833990435844),\n",
       "   ('310', 0.055507300327755874),\n",
       "   ('494', 0.05172607032835904),\n",
       "   ('387', 0.048155134487581276),\n",
       "   ('541', 0.046469385691389871),\n",
       "   ('373', 0.034095712743052647),\n",
       "   ('249', 0.032555277607797375),\n",
       "   ('52', 0.031052897256233249),\n",
       "   ('511', 0.029919438569389754)]),\n",
       " (7,\n",
       "  [('557', 0.08177954964575003),\n",
       "   ('76', 0.078292446313770969),\n",
       "   ('112', 0.077667498894694445),\n",
       "   ('54', 0.074795416144399496),\n",
       "   ('17', 0.046269919883313013),\n",
       "   ('358', 0.045011744057166202),\n",
       "   ('100', 0.032743877728247918),\n",
       "   ('190', 0.030689963401448681),\n",
       "   ('193', 0.027637975572910353),\n",
       "   ('141', 0.02761016321923896)]),\n",
       " (8,\n",
       "  [('23', 0.08913559323103494),\n",
       "   ('471', 0.058525674568304743),\n",
       "   ('17', 0.0567709266837833),\n",
       "   ('456', 0.056643125766547141),\n",
       "   ('29', 0.051001953714775665),\n",
       "   ('352', 0.048618610425553044),\n",
       "   ('1286', 0.041425683943082568),\n",
       "   ('1090', 0.03331124701755242),\n",
       "   ('1255', 0.026614577314933135),\n",
       "   ('1040', 0.025854417370906515)]),\n",
       " (9,\n",
       "  [('83', 0.075342381796705313),\n",
       "   ('45', 0.074329638714682011),\n",
       "   ('4', 0.064527494639078087),\n",
       "   ('478', 0.057586706427703444),\n",
       "   ('17', 0.055227627166097172),\n",
       "   ('229', 0.052823762545033945),\n",
       "   ('321', 0.050453963492686785),\n",
       "   ('230', 0.041173798711935133),\n",
       "   ('345', 0.040113136640874132),\n",
       "   ('54', 0.036316249841425459)]),\n",
       " (10,\n",
       "  [('12', 0.039518669326397929),\n",
       "   ('990', 0.038478006722796027),\n",
       "   ('204', 0.036828203452286608),\n",
       "   ('504', 0.03651984036432307),\n",
       "   ('114', 0.032470689729042899),\n",
       "   ('21', 0.032108792183435729),\n",
       "   ('514', 0.028590013542548851),\n",
       "   ('624', 0.028079719203308467),\n",
       "   ('17', 0.025318922727320548),\n",
       "   ('117', 0.024757534396345857)]),\n",
       " (11,\n",
       "  [('58', 0.065601824097514166),\n",
       "   ('17', 0.064436314445619494),\n",
       "   ('110', 0.049230196150176486),\n",
       "   ('74', 0.040356655479829931),\n",
       "   ('4', 0.033949493378055487),\n",
       "   ('8', 0.033907681758099682),\n",
       "   ('54', 0.033125607095506854),\n",
       "   ('839', 0.03157851451251361),\n",
       "   ('111', 0.030626995840766048),\n",
       "   ('46', 0.028928350420480115)]),\n",
       " (12,\n",
       "  [('536', 0.10243052517819116),\n",
       "   ('569', 0.067829707044085627),\n",
       "   ('1044', 0.047469848852872185),\n",
       "   ('530', 0.043669577154559033),\n",
       "   ('7', 0.038742872508497624),\n",
       "   ('1743', 0.038316178958402412),\n",
       "   ('600', 0.036098289648824756),\n",
       "   ('876', 0.032771886250913991),\n",
       "   ('8', 0.031295865412231998),\n",
       "   ('1043', 0.029412540211151559)]),\n",
       " (13,\n",
       "  [('272', 0.082918042314723758),\n",
       "   ('577', 0.055886774498961844),\n",
       "   ('246', 0.048811191090141433),\n",
       "   ('201', 0.047371005951654138),\n",
       "   ('520', 0.037834110368553199),\n",
       "   ('33', 0.037711510131529152),\n",
       "   ('231', 0.032931821407080737),\n",
       "   ('46', 0.029534198334413311),\n",
       "   ('69', 0.023859060428696736),\n",
       "   ('71', 0.023757514320805515)]),\n",
       " (14,\n",
       "  [('432', 0.074361290574771532),\n",
       "   ('128', 0.064709517509297973),\n",
       "   ('431', 0.051286762417502609),\n",
       "   ('228', 0.047840135838041926),\n",
       "   ('524', 0.045801256103689743),\n",
       "   ('864', 0.043480399976897691),\n",
       "   ('48', 0.042721616099810546),\n",
       "   ('622', 0.035706842908967834),\n",
       "   ('29', 0.035612496580962681),\n",
       "   ('819', 0.027852454090670546)]),\n",
       " (15,\n",
       "  [('318', 0.090734962149585235),\n",
       "   ('275', 0.078428146581194874),\n",
       "   ('949', 0.059521887589701755),\n",
       "   ('205', 0.057504455159495795),\n",
       "   ('496', 0.032885978647542766),\n",
       "   ('48', 0.031225445699347047),\n",
       "   ('756', 0.029739867566467668),\n",
       "   ('385', 0.026984144757307694),\n",
       "   ('1607', 0.026318671747296053),\n",
       "   ('1020', 0.023750973353692507)]),\n",
       " (16,\n",
       "  [('79', 0.099902670071229466),\n",
       "   ('100', 0.059694488447186951),\n",
       "   ('54', 0.049592761943570936),\n",
       "   ('59', 0.046717431081104828),\n",
       "   ('250', 0.039661070725561375),\n",
       "   ('17', 0.037576397608641114),\n",
       "   ('309', 0.036701832035566026),\n",
       "   ('106', 0.036694064891409361),\n",
       "   ('251', 0.031758803696150487),\n",
       "   ('12', 0.030003678547466685)]),\n",
       " (17,\n",
       "  [('357', 0.12172719188207466),\n",
       "   ('313', 0.050322656740338492),\n",
       "   ('237', 0.046404280823440891),\n",
       "   ('4', 0.042843658714661358),\n",
       "   ('11', 0.039783200318437753),\n",
       "   ('45', 0.037203539263801613),\n",
       "   ('62', 0.033229906419914391),\n",
       "   ('242', 0.030622889442469225),\n",
       "   ('678', 0.028938052142979006),\n",
       "   ('17', 0.026125153488940806)]),\n",
       " (18,\n",
       "  [('17', 0.10381742377231951),\n",
       "   ('117', 0.092698866562907226),\n",
       "   ('13', 0.085916104113918923),\n",
       "   ('18', 0.084900076429446317),\n",
       "   ('21', 0.070842980922765128),\n",
       "   ('49', 0.055141366445864662),\n",
       "   ('48', 0.048884950881228503),\n",
       "   ('63', 0.037273124504661019),\n",
       "   ('311', 0.0341814393250153),\n",
       "   ('289', 0.029932045710411054)]),\n",
       " (19,\n",
       "  [('273', 0.13970899488628455),\n",
       "   ('556', 0.073674612535929634),\n",
       "   ('534', 0.067054199882760387),\n",
       "   ('405', 0.05465638966605977),\n",
       "   ('132', 0.047987075551798597),\n",
       "   ('247', 0.039082838332851491),\n",
       "   ('578', 0.038164347288332533),\n",
       "   ('473', 0.032741853959775483),\n",
       "   ('1300', 0.027371469452021849),\n",
       "   ('1848', 0.024063317965376401)]),\n",
       " (20,\n",
       "  [('212', 0.041046011514613408),\n",
       "   ('150', 0.034393463200642335),\n",
       "   ('386', 0.033107556094563596),\n",
       "   ('153', 0.030468005156074361),\n",
       "   ('56', 0.030403027092151761),\n",
       "   ('223', 0.028918536943893805),\n",
       "   ('177', 0.027942786850001924),\n",
       "   ('668', 0.026892920742325098),\n",
       "   ('198', 0.024413040274517774),\n",
       "   ('1081', 0.024252269655066268)]),\n",
       " (21,\n",
       "  [('681', 0.11404346022050108),\n",
       "   ('328', 0.10488716699395914),\n",
       "   ('16', 0.065801514849129938),\n",
       "   ('25', 0.06120996891627923),\n",
       "   ('437', 0.059105116450507325),\n",
       "   ('329', 0.042784937871100992),\n",
       "   ('490', 0.040729389468642005),\n",
       "   ('502', 0.034774850249789852),\n",
       "   ('1400', 0.030566919039513724),\n",
       "   ('916', 0.027018287162535629)]),\n",
       " (22,\n",
       "  [('1125', 0.076484565334487456),\n",
       "   ('1242', 0.051722839994964936),\n",
       "   ('415', 0.051441576007081491),\n",
       "   ('86', 0.045772655424796735),\n",
       "   ('858', 0.039208297087295306),\n",
       "   ('70', 0.029934730024417922),\n",
       "   ('579', 0.026904430708833579),\n",
       "   ('797', 0.025322407139363963),\n",
       "   ('969', 0.025313247817361786),\n",
       "   ('757', 0.023751920392447019)]),\n",
       " (23,\n",
       "  [('37', 0.18326330575630412),\n",
       "   ('376', 0.084629991017165382),\n",
       "   ('232', 0.052220226754950277),\n",
       "   ('89', 0.042124933666680582),\n",
       "   ('1004', 0.041906941132415831),\n",
       "   ('1874', 0.039895850346995179),\n",
       "   ('1170', 0.038647523546880537),\n",
       "   ('822', 0.02941607656752681),\n",
       "   ('25', 0.029005088126472692),\n",
       "   ('274', 0.028270566448090301)]),\n",
       " (24,\n",
       "  [('302', 0.076151977039109239),\n",
       "   ('48', 0.066835860896271304),\n",
       "   ('1078', 0.064918730726886573),\n",
       "   ('774', 0.060718297168320126),\n",
       "   ('446', 0.056379713014674905),\n",
       "   ('452', 0.0385846857447492),\n",
       "   ('1348', 0.037261579316190417),\n",
       "   ('1218', 0.033911196322114853),\n",
       "   ('2029', 0.02703397274380993),\n",
       "   ('29', 0.026768980873337157)]),\n",
       " (25,\n",
       "  [('17', 0.06733575002206621),\n",
       "   ('276', 0.061223398173519378),\n",
       "   ('45', 0.054472869353531315),\n",
       "   ('346', 0.04354014324384714),\n",
       "   ('44', 0.043030728188749784),\n",
       "   ('22', 0.039810784845899935),\n",
       "   ('33', 0.032672345021430016),\n",
       "   ('19', 0.03131821810348423),\n",
       "   ('41', 0.028568610905595839),\n",
       "   ('645', 0.027942581160366197)]),\n",
       " (26,\n",
       "  [('223', 0.084100145112892474),\n",
       "   ('57', 0.047994943420107197),\n",
       "   ('48', 0.042100642989395684),\n",
       "   ('108', 0.036585745943818596),\n",
       "   ('4', 0.035762433194437095),\n",
       "   ('9', 0.032097300202764599),\n",
       "   ('343', 0.031522691162217398),\n",
       "   ('43', 0.031137737607498189),\n",
       "   ('29', 0.027963220942795571),\n",
       "   ('125', 0.027937803804461935)]),\n",
       " (27,\n",
       "  [('190', 0.10396706142744759),\n",
       "   ('396', 0.057124652005232021),\n",
       "   ('17', 0.053733918944142006),\n",
       "   ('394', 0.046618119317498902),\n",
       "   ('54', 0.044407381546774573),\n",
       "   ('758', 0.039254857112094026),\n",
       "   ('861', 0.037814064869849472),\n",
       "   ('262', 0.036439138055697928),\n",
       "   ('134', 0.031405210510355538),\n",
       "   ('13', 0.030968526762209986)]),\n",
       " (28,\n",
       "  [('210', 0.19508924356569163),\n",
       "   ('68', 0.055556756114979025),\n",
       "   ('938', 0.054056424855559233),\n",
       "   ('342', 0.033169600156391026),\n",
       "   ('182', 0.032021518520942385),\n",
       "   ('516', 0.030648426681834071),\n",
       "   ('427', 0.030446873755399298),\n",
       "   ('362', 0.028375637337907291),\n",
       "   ('395', 0.027884097242210148),\n",
       "   ('1060', 0.024196290354968709)]),\n",
       " (29,\n",
       "  [('43', 0.1463048662743229),\n",
       "   ('84', 0.104363066956128),\n",
       "   ('475', 0.064335521123798964),\n",
       "   ('21', 0.039057623143295014),\n",
       "   ('306', 0.038482161795683791),\n",
       "   ('54', 0.038478580284593451),\n",
       "   ('898', 0.032462396795093863),\n",
       "   ('309', 0.026672423997691031),\n",
       "   ('1209', 0.025707563650688586),\n",
       "   ('55', 0.020185619633315697)]),\n",
       " (30,\n",
       "  [('312', 0.087493917347990488),\n",
       "   ('204', 0.085537324663147521),\n",
       "   ('48', 0.069363041514929294),\n",
       "   ('17', 0.055987831911700973),\n",
       "   ('117', 0.049871563267393393),\n",
       "   ('191', 0.047896027253636016),\n",
       "   ('459', 0.038214889644264359),\n",
       "   ('53', 0.03442261308263507),\n",
       "   ('439', 0.034160118556360253),\n",
       "   ('365', 0.029040139179242974)]),\n",
       " (31,\n",
       "  [('206', 0.068312059378858092),\n",
       "   ('17', 0.06507121716220253),\n",
       "   ('308', 0.056469473229702138),\n",
       "   ('501', 0.049571460055164836),\n",
       "   ('97', 0.04493808117817568),\n",
       "   ('29', 0.041723538838178031),\n",
       "   ('234', 0.033809391165539576),\n",
       "   ('1276', 0.033698947511594114),\n",
       "   ('279', 0.032453738237110522),\n",
       "   ('477', 0.030842398842567949)]),\n",
       " (32,\n",
       "  [('101', 0.066664612948272847),\n",
       "   ('171', 0.055994089782032283),\n",
       "   ('826', 0.054040182620818687),\n",
       "   ('29', 0.053238092758952249),\n",
       "   ('334', 0.046107316341118892),\n",
       "   ('254', 0.037428932421313961),\n",
       "   ('482', 0.034378270783299809),\n",
       "   ('630', 0.032440550174626569),\n",
       "   ('633', 0.030424351510590197),\n",
       "   ('484', 0.028961030574490773)]),\n",
       " (33,\n",
       "  [('390', 0.14181458850878584),\n",
       "   ('179', 0.074719822452333412),\n",
       "   ('1068', 0.066835766685314976),\n",
       "   ('164', 0.053874158247288924),\n",
       "   ('1091', 0.040394869773817281),\n",
       "   ('1314', 0.034275485365545748),\n",
       "   ('1311', 0.033296853017633653),\n",
       "   ('1024', 0.020500702324686752),\n",
       "   ('519', 0.020492200778908665),\n",
       "   ('1987', 0.018740471546946948)]),\n",
       " (34,\n",
       "  [('45', 0.08155109254197819),\n",
       "   ('17', 0.067489810507209189),\n",
       "   ('4', 0.059224022428398394),\n",
       "   ('54', 0.050751059212544691),\n",
       "   ('252', 0.045523914446054539),\n",
       "   ('12', 0.043249016512209595),\n",
       "   ('256', 0.04246932504054144),\n",
       "   ('315', 0.038944088491152988),\n",
       "   ('733', 0.037108582102051396),\n",
       "   ('208', 0.034503494844969951)]),\n",
       " (35,\n",
       "  [('26', 0.095884178906728762),\n",
       "   ('95', 0.051021911260369),\n",
       "   ('48', 0.041969978912902328),\n",
       "   ('98', 0.040218575795226044),\n",
       "   ('4', 0.039011029548583404),\n",
       "   ('231', 0.035681533159697812),\n",
       "   ('94', 0.034480908543302387),\n",
       "   ('361', 0.0331045462272948),\n",
       "   ('29', 0.029556424258569854),\n",
       "   ('17', 0.029134539153088647)]),\n",
       " (36,\n",
       "  [('203', 0.10535357214278764),\n",
       "   ('656', 0.062590095130728468),\n",
       "   ('1222', 0.059109840660583217),\n",
       "   ('174', 0.056178959624412647),\n",
       "   ('280', 0.042150965149258771),\n",
       "   ('933', 0.039745159421602241),\n",
       "   ('148', 0.039073551631640835),\n",
       "   ('566', 0.037419987842312069),\n",
       "   ('1228', 0.036411913726136211),\n",
       "   ('740', 0.032610197619603952)]),\n",
       " (37,\n",
       "  [('144', 0.21498303829127222),\n",
       "   ('140', 0.13265838649356201),\n",
       "   ('91', 0.085582703136326418),\n",
       "   ('45', 0.045360932787653865),\n",
       "   ('4', 0.043766692457698375),\n",
       "   ('0', 0.02551138753552314),\n",
       "   ('1211', 0.025503150336289724),\n",
       "   ('521', 0.025212020868972337),\n",
       "   ('54', 0.022245611171442404),\n",
       "   ('225', 0.019829703670637942)]),\n",
       " (38,\n",
       "  [('54', 0.06776591203119392),\n",
       "   ('489', 0.060467376668503457),\n",
       "   ('17', 0.057660572224498774),\n",
       "   ('4', 0.039352923775599194),\n",
       "   ('552', 0.038413799056435931),\n",
       "   ('712', 0.037783423124367992),\n",
       "   ('79', 0.036410616604633364),\n",
       "   ('0', 0.031463664431954481),\n",
       "   ('6', 0.029156856938582908),\n",
       "   ('19', 0.029063415938801636)]),\n",
       " (39,\n",
       "  [('81', 0.10231332541491255),\n",
       "   ('78', 0.091408676847404835),\n",
       "   ('146', 0.061580403945851472),\n",
       "   ('73', 0.046314963974819746),\n",
       "   ('100', 0.045822047220113821),\n",
       "   ('9', 0.031157317885442883),\n",
       "   ('729', 0.031153693112407507),\n",
       "   ('277', 0.028540075823185872),\n",
       "   ('34', 0.026516317482756461),\n",
       "   ('12', 0.024392903833583286)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = lda.show_topics(num_topics=40, num_words=10, log=False, formatted=False)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['17', '116', '100', '54', '279', '119', '307', '29', '38', '12',\n",
       "       '195', '45', '178', '124', '211', '29', '958', '705', '17', '1493',\n",
       "       '770', '830', '1338', '480', '3', '1637', '816', '806', '117',\n",
       "       '1201', '41', '207', '17', '383', '0', '45', '155', '29', '425',\n",
       "       '397', '200', '20', '17', '39', '45', '348', '183', '236', '216',\n",
       "       '12', '46', '17', '113', '183', '54', '45', '4', '39', '100', '127',\n",
       "       '51', '366', '310', '494', '387', '541', '373', '249', '52', '511',\n",
       "       '557', '76', '112', '54', '17', '358', '100', '190', '193', '141',\n",
       "       '23', '471', '17', '456', '29', '352', '1286', '1090', '1255',\n",
       "       '1040', '83', '45', '4', '478', '17', '229', '321', '230', '345',\n",
       "       '54', '12', '990', '204', '504', '114', '21', '514', '624', '17',\n",
       "       '117', '58', '17', '110', '74', '4', '8', '54', '839', '111', '46',\n",
       "       '536', '569', '1044', '530', '7', '1743', '600', '876', '8', '1043',\n",
       "       '272', '577', '246', '201', '520', '33', '231', '46', '69', '71',\n",
       "       '432', '128', '431', '228', '524', '864', '48', '622', '29', '819',\n",
       "       '318', '275', '949', '205', '496', '48', '756', '385', '1607',\n",
       "       '1020', '79', '100', '54', '59', '250', '17', '309', '106', '251',\n",
       "       '12', '357', '313', '237', '4', '11', '45', '62', '242', '678',\n",
       "       '17', '17', '117', '13', '18', '21', '49', '48', '63', '311', '289',\n",
       "       '273', '556', '534', '405', '132', '247', '578', '473', '1300',\n",
       "       '1848', '212', '150', '386', '153', '56', '223', '177', '668',\n",
       "       '198', '1081', '681', '328', '16', '25', '437', '329', '490', '502',\n",
       "       '1400', '916', '1125', '1242', '415', '86', '858', '70', '579',\n",
       "       '797', '969', '757', '37', '376', '232', '89', '1004', '1874',\n",
       "       '1170', '822', '25', '274', '302', '48', '1078', '774', '446',\n",
       "       '452', '1348', '1218', '2029', '29', '17', '276', '45', '346', '44',\n",
       "       '22', '33', '19', '41', '645', '223', '57', '48', '108', '4', '9',\n",
       "       '343', '43', '29', '125', '190', '396', '17', '394', '54', '758',\n",
       "       '861', '262', '134', '13', '210', '68', '938', '342', '182', '516',\n",
       "       '427', '362', '395', '1060', '43', '84', '475', '21', '306', '54',\n",
       "       '898', '309', '1209', '55', '312', '204', '48', '17', '117', '191',\n",
       "       '459', '53', '439', '365', '206', '17', '308', '501', '97', '29',\n",
       "       '234', '1276', '279', '477', '101', '171', '826', '29', '334',\n",
       "       '254', '482', '630', '633', '484', '390', '179', '1068', '164',\n",
       "       '1091', '1314', '1311', '1024', '519', '1987', '45', '17', '4',\n",
       "       '54', '252', '12', '256', '315', '733', '208', '26', '95', '48',\n",
       "       '98', '4', '231', '94', '361', '29', '17', '203', '656', '1222',\n",
       "       '174', '280', '933', '148', '566', '1228', '740', '144', '140',\n",
       "       '91', '45', '4', '0', '1211', '521', '54', '225', '54', '489', '17',\n",
       "       '4', '552', '712', '79', '0', '6', '19', '81', '78', '146', '73',\n",
       "       '100', '9', '729', '277', '34', '12'], \n",
       "      dtype='|S15')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"]\n",
    "wordsid = [str(dictionary.token2id[i]) for i in words]\n",
    "# dictionary.id2token[0]\n",
    "# dictionary.token2id['sugar']\n",
    "data = [i[1] for i in top]\n",
    "data = np.array(data)\n",
    "# data[0][:,0]\n",
    "occur = data[:,:,0].flatten()\n",
    "# data.reshape((40, 10))\n",
    "occur\n",
    "# wordsid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 7, 10, 1, 1, 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##eigenein's method:\n",
    "# ans = [0] * 6\n",
    "# wordsid = {str(dictionary.token2id[i]):0 for i in words}\n",
    "# for w in occur:\n",
    "#     if w in wordsid:\n",
    "#         wordsid[w] += 1\n",
    "\n",
    "# ans = [0] * 6\n",
    "# wordsid = {str(dictionary.token2id[i]) for i in words}\n",
    "# for w in occur:\n",
    "#     for i, wordid in enumerate(wordsid):\n",
    "    \n",
    "\n",
    "# wordsid\n",
    "import collections\n",
    "wordsid = [str(dictionary.token2id[i]) for i in words]\n",
    "dat = collections.Counter(occur)\n",
    "ans = [dat[i] for i in wordsid]\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 7, 10, 1, 1, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['14', '50', '29', '85', '734', '11']\n",
    "ans = [0 for _ in range(6)]\n",
    "for w in occur:\n",
    "    for i in range(len(wordsid)):\n",
    "        if w == wordsid[i]:\n",
    "            ans[i] += 1\n",
    "# for i in occur:\n",
    "#     if i == '11':\n",
    "#         print(i)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary.id2token[1]\n",
    "#['15', '47', '29', '87', '734', '19']\n",
    "#[21, 9, 7, 0, 0, 2]\n",
    "# wordsid\n",
    "# dictionary.id2token[11]\n",
    "#py3: [20, 8, 8, 0, 1, 2]; [21, 9, 9, 0, 1, 3]\n",
    "#THIS IS THE CORRECT ANSWER:\n",
    "#[20, 7, 10, 1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1_upd2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers1(20, 7, 10, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами - фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)\n",
    "# dictionary2.id2token[2]\n",
    "dictionary2.token2id['salt']\n",
    "dictionary.dfs\n",
    "# dictionary2.id2token[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary.id2token[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная dfs - это словарь, ключами которого являются id токена, а элементами - число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря filter_tokens, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after - размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after - суммарное количество ингредиентов в корпусе до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_before = len(dictionary2.dfs)\n",
    "good = [i for i in dictionary2.dfs.keys() if dictionary2.dfs[i] > 4000]\n",
    "# print(good)\n",
    "# print([dictionary2.id2token[i] for i in good])\n",
    "\n",
    "dictionary2.filter_tokens(good)\n",
    "dict_after = len(dictionary2.dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dict_before, dict_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# corpus_before = len(corpus)\n",
    "corpus_before = np.sum([len(i) for i in corpus])\n",
    "\n",
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]\n",
    "corpus_after = np.sum([len(i) for i in corpus2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(corpus_before, corpus_after)\n",
    "print(corpus_before, corpus_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))\n",
    "        \n",
    "save_answers2(dict_before, dict_after, corpus_before, corpus_after)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictioanary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом top_topics модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "lda2 = models.LdaModel(corpus=corpus2, num_topics=40, iterations=50, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coher2 = lda2.top_topics(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coher2 = np.array(coher2)\n",
    "c2 = coher2[:,1].mean()\n",
    "c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coher1 = lda.top_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coher1 = np.array(coher1)\n",
    "c1 = coher1[:,1].mean()\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))\n",
    "save_answers3(c1, c2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом get_document_topics второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2.get_document_topics(corpus2[0])\n",
    "# lda2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной .alpha второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod2 = 0\n",
    "for c in corpus2:\n",
    "    p = lda2.get_document_topics(c, minimum_probability=0.01)\n",
    "    mod2 += len(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "lda3 = models.LdaModel(corpus=corpus2, num_topics=40, passes=5, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod3 = 0\n",
    "for c in corpus2:\n",
    "    p = lda3.get_document_topics(c, minimum_probability=0.01)\n",
    "    mod3 += len(p)\n",
    "mod3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_answers4(mod2, mod3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр alpha влияет на разреженность распределений тем в документах. Аналогично гиперпараметр eta влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = [rec['cuisine'] for rec in recipes]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(lda2.get_document_topics(corpus2, minimum_probability=0.01))\n",
    "t = lda2.get_document_topics(corpus2[10])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in t:\n",
    "    print i[0], i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(corpus2), len(dictionary2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(corpus2)):\n",
    "    topics = lda2.get_document_topics(corpus2[i])\n",
    "    for t in topics:\n",
    "        X[i][t[0]] += t[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))\n",
    "save_answers5(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10-15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA --- вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу A размера темы x кухни, ее элементы $a_{tc}$ - суммы p(t|d) по всем документам d, которые отнесены к кухне c. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу A. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
