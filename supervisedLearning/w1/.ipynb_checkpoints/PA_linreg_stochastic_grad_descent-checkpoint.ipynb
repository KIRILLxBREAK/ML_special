{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\frac{1}{\\ell}\\sum_{i=1}^\\ell{{(y_i - (w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}))}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$w_0 \\leftarrow w_0 + \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{(y_i - (w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}))}}$$\n",
    "$$w_j \\leftarrow w_j + \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}(y_i - (w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}))}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "У градиентного спуска, описанного выше, есть один недостаток. На больших выборках вычисление градиента по всем имеющимся данным на каждом шаге может быть вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$w_0 \\leftarrow w_0 + \\frac{2\\eta}{\\ell} {(y_k - (w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}))}$$\n",
    "$$w_j \\leftarrow w_j + \\frac{2\\eta}{\\ell} {x_{kj}(y_k - (w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}))},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, соответствующий целевому признаку, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = adver_data[['TV', 'Radio', 'Newspaper']].values\n",
    "y = adver_data['Sales'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "means, stds = np.mean(X,axis=0), np.std(X,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (X - means) / stds# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ones = np.ones(len(X)).reshape((X.shape[0],1))\n",
    "X1 = np.hstack([X, ones])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    a = sum((y - y_pred)**2)/len(y)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.345749999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymed = np.ones(len(y))*np.median(y)\n",
    "answer1 = mserror(y, ymed)\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, ymed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "     npsolv = np.linalg.lstsq(X,y)\n",
    "     return npsolv[0]\n",
    "# from scipy.stats import linregress\n",
    "# npsolv = np.linalg.lstsq(X,y)\n",
    "\n",
    "# npsolv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "654.58525854990501"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X1, y)\n",
    "print(norm_eq_weights)\n",
    "# \n",
    "s = list(means)\n",
    "s.append(1)\n",
    "np.dot(s,norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([0,0,0,1],norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    # Ваш код здесь\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X1, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03513943  0.02489335  0.01783625  0.13921071]\n",
      "219.35632403\n",
      "0.00600187640385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9ec44e0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJK+iEiMKOmLiMSIkr6ISIz8P8ir5IstBlx3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7991748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    # Ваш код здесь\n",
    "    w_new = w + 2*eta/len(X)*X[train_ind]*(y[train_ind] - np.dot(X[train_ind],w))\n",
    "#     w0_new = w[-1] + 2*eta/len(X)*(y[train_ind] - np.dot(X[train_ind],w))\n",
    "#     wr_new = w[:-1] + 2*eta/len(X)*X[train_ind][:-1]*(y[train_ind] - np.dot(X[train_ind],w))\n",
    "\n",
    "#     print(w0_new)\n",
    "#     print(wr_new)\n",
    "    return w_new#np.concatenate((wr_new, [w0_new]))\n",
    "\n",
    "w = [0,0,0,0]\n",
    "# w_new = stochastic_gradient_step(X1, y, w, 3)\n",
    "# np.linalg.norm(w_new-w)\n",
    "# print(w_new)\n",
    "# print(w)\n",
    "N = 100\n",
    "dist = []\n",
    "errors = []\n",
    "iters = [i for i in range(N)]\n",
    "for i in range(N):\n",
    "    random_ind = np.random.randint(X1.shape[0])\n",
    "    w_new = stochastic_gradient_step(X1, y, w, random_ind)\n",
    "    err = mserror(y, linear_prediction(X1, w_new))\n",
    "    nor = np.linalg.norm(w_new-w)\n",
    "    errors.append(err)\n",
    "    dist.append(nor)\n",
    "    w = w_new\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(w)\n",
    "print(err)\n",
    "print(nor)\n",
    "plt.plot(iters,errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##ne3x7 code:\n",
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    return w + X[train_ind] * 2 * eta * (y[train_ind] - X[train_ind].dot(w)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.51615499,  1.52846331,  1.78354865,  1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e5,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        errors.append(mserror(y, linear_prediction(X, w)))\n",
    "        w_new = stochastic_gradient_step(X, y, w, random_ind)\n",
    "        weight_dist = np.linalg.norm(w_new-w)\n",
    "        w = w_new\n",
    "        iter_num += 1\n",
    "        # Ваш код здесь\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##ne3x7 code:\n",
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    weight_dist = np.inf\n",
    "    w = w_init\n",
    "    errors = []\n",
    "    iter_num = 0\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        old_w = w\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        w = stochastic_gradient_step(X, y, w, random_ind, eta)\n",
    "        errors.append(mserror(y, linear_prediction(X, w)))\n",
    "        \n",
    "        iter_num += 1\n",
    "        weight_dist = np.linalg.norm(w - old_w)\n",
    "        \n",
    "        if (verbose):\n",
    "            with open('log.txt', 'a') as logfile:\n",
    "                logfile.write(\"Step %d: old_w = %s, w = %s, error = %s\\n\" % (iter_num, old_w, w, errors[iter_num - 1]))\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X1, y, [0,0,0,0],max_iter=1e5)# Ваш код здесь\n",
    "print(stoch_errors_by_iter[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xe99beb8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1ys+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbf30d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84501"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights\n",
    "len(stoch_errors_by_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7844125883527586"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258835\n"
     ]
    }
   ],
   "source": [
    "answer4 = stoch_errors_by_iter[-1]\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
